{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3a20c1",
   "metadata": {},
   "source": [
    "# ğŸ§ª Benchmark ONNX vs OpenVINO (FP32 & INT8)\n",
    "ModÃ¨le : exportÃ© depuis Paddle, dÃ©jÃ  au format ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Install required packages\n",
    "\n",
    "# Upgrade pip\n",
    "%pip install --upgrade pip\n",
    "# Install PyTorch for CPU\n",
    "%pip install -q torch==2.7.0 torchvision==0.22.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "# Install OpenVINO\n",
    "%pip install -q \"openvino==2025.1.0\" nncf==2.16.0\n",
    "# Install ONNX Runtime\n",
    "%pip install -q onnx==1.18.0 onnxruntime==1.22.0\n",
    "# Install other dependencies\n",
    "%pip install -q tqdm==4.67.1 opencv-python==4.11.0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bfaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import onnx\n",
    "import nncf\n",
    "import math\n",
    "import cv2\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "import openvino as ov\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onnx_model_input_shapes(model_path):\n",
    "    model = onnx.load(model_path)\n",
    "    graph = model.graph\n",
    "    input_info = {}\n",
    "    for input_tensor in graph.input:\n",
    "        name = input_tensor.name\n",
    "        shape = []\n",
    "        tensor_type = input_tensor.type.tensor_type\n",
    "        if tensor_type.HasField(\"shape\"):\n",
    "            for dim in tensor_type.shape.dim:\n",
    "                if dim.HasField(\"dim_value\"):\n",
    "                    shape.append(dim.dim_value)\n",
    "                elif dim.HasField(\"dim_param\"):\n",
    "                    shape.append(dim.dim_param)\n",
    "                else:\n",
    "                    shape.append(\"?\")\n",
    "        else:\n",
    "            shape.append(\"?\")\n",
    "        input_info[name] = shape\n",
    "    return input_info\n",
    "\n",
    "# Paths to models\n",
    "det_model_path = \"../models/en_PP-OCRv3_det.onnx\"\n",
    "rec_model_path = \"../models/model_en_rec_v4.onnx\"\n",
    "\n",
    "# Output directory\n",
    "quantized_models_dir = \"../models\"\n",
    "os.makedirs(quantized_models_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "inputs = get_onnx_model_input_shapes(det_model_path)\n",
    "print(f\"Input shapes for model {det_model_path}:\")\n",
    "for name, shape in inputs.items():\n",
    "    print(f\" - {name}: {shape}\")\n",
    "\n",
    "inputs = get_onnx_model_input_shapes(det_model_path)\n",
    "print(f\"Input shapes for model {rec_model_path}:\")\n",
    "for name, shape in inputs.items():\n",
    "    print(f\" - {name}: {shape}\")\n",
    "\n",
    "# Input shapes for each model\n",
    "input_shapes = {\n",
    "    \"en_PP-OCRv3_det.onnx\": (640, 640, 3),\n",
    "    \"model_en_rec_v4.onnx\": (640, 640, 3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‚ Download CIFAR-10 Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_dataset = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_onnx_to_openvino(onnx_model_path: str, output_dir: str = \"../models\"):\n",
    "    print(f\"Converting ONNX model to OpenVINO IR: {onnx_model_path}\")\n",
    "    \n",
    "    # Conversion\n",
    "    model = ov.convert_model(onnx_model_path)\n",
    "\n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save the model in OpenVINO IR format\n",
    "    model_name = Path(onnx_model_path).stem + \"_openvino_fp32\"\n",
    "    xml_path = str(Path(output_dir) / f\"{model_name}.xml\")\n",
    "    ov.save_model(model, xml_path)\n",
    "\n",
    "    print(f\"Model saved to: {xml_path}\")\n",
    "\n",
    "convert_onnx_to_openvino(det_model_path)\n",
    "convert_onnx_to_openvino(rec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c622ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_norm_img_rec(img):\n",
    "    imgW = 320\n",
    "    imgH = 48\n",
    "    img_h, img_w = img.shape[0], img.shape[1]\n",
    "    new_ratio = max((imgW/ imgH), ((img_w * 1.0) / img_h))\n",
    "    imgW = int((imgH * new_ratio))\n",
    "    h, w = img.shape[:2]\n",
    "    ratio = w / float(h)\n",
    "    if math.ceil(imgH * ratio) > imgW:\n",
    "        resized_w = imgW\n",
    "    else:\n",
    "        resized_w = int(math.ceil(imgH * ratio))\n",
    "    resized_image = cv2.resize(img, (resized_w, imgH))\n",
    "    resized_image = resized_image.astype('float32')\n",
    "    resized_image = resized_image.transpose((2, 0, 1)) / 255\n",
    "    resized_image -= 0.5\n",
    "    resized_image /= 0.5\n",
    "    padding_im = np.zeros((3, imgH, imgW), dtype=np.float32)\n",
    "    padding_im[:, :, 0:resized_w] = resized_image\n",
    "    return padding_im\n",
    "\n",
    "def resize_image_det(img, limit_side_len = 960,limit_type ='max'):\n",
    "        \"\"\"\n",
    "        resize image to a size multiple of 32 which is required by the network\n",
    "        args:\n",
    "            img(array): array with shape [h, w, c]\n",
    "        return(tuple):\n",
    "            img, (ratio_h, ratio_w)\n",
    "        \"\"\"\n",
    "        limit_side_len = limit_side_len\n",
    "        h, w, c = img.shape\n",
    "\n",
    "        # limit the max side\n",
    "        if limit_type == 'max':\n",
    "            if max(h, w) > limit_side_len:\n",
    "                if h > w:\n",
    "                    ratio = float(limit_side_len) / h\n",
    "                else:\n",
    "                    ratio = float(limit_side_len) / w\n",
    "            else:\n",
    "                ratio = 1.\n",
    "        elif limit_type == 'min':\n",
    "            if min(h, w) < limit_side_len:\n",
    "                if h < w:\n",
    "                    ratio = float(limit_side_len) / h\n",
    "                else:\n",
    "                    ratio = float(limit_side_len) / w\n",
    "            else:\n",
    "                ratio = 1.\n",
    "        elif limit_type == 'resize_long':\n",
    "            ratio = float(limit_side_len) / max(h, w)\n",
    "        else:\n",
    "            raise Exception('not support limit type, image ')\n",
    "        resize_h = int(h * ratio)\n",
    "        resize_w = int(w * ratio)\n",
    "\n",
    "        resize_h = max(int(round(resize_h / 32) * 32), 32)\n",
    "        resize_w = max(int(round(resize_w / 32) * 32), 32)\n",
    "\n",
    "        try:\n",
    "            if int(resize_w) <= 0 or int(resize_h) <= 0:\n",
    "                return None, (None, None)\n",
    "            img = cv2.resize(img, (int(resize_w), int(resize_h)))\n",
    "        except:\n",
    "            return None, None\n",
    "        ratio_h = resize_h / float(h)\n",
    "        ratio_w = resize_w / float(w)\n",
    "        return img.transpose((2, 0, 1))\n",
    "\n",
    "# Benchmark ONNX Runtime FP32 optimized\n",
    "def benchmark_onnxruntime(model_path, input_shape, n_runs=100):\n",
    "    print(f\"\\nBenchmarking ONNX Runtime model: {model_path}\")\n",
    "    sess_options = ort.SessionOptions()\n",
    "    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    sess_options.enable_mem_pattern = True\n",
    "    sess_options.execution_mode = ort.ExecutionMode.ORT_PARALLEL\n",
    "\n",
    "    session = ort.InferenceSession(model_path, sess_options=sess_options)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "    #input_data = cv2.imread(\"test.png\").astype(np.float32)\n",
    "\n",
    "    if \"rec\" in model_path:\n",
    "        input_data = resize_norm_img_rec(input_data)\n",
    "    if \"det\" in model_path:\n",
    "        input_data = resize_image_det(input_data)\n",
    "\n",
    "    # VÃ©rifiez que input_data est un tableau NumPy\n",
    "    if not isinstance(input_data, np.ndarray):\n",
    "        input_data = np.array(input_data)\n",
    "\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    \n",
    "    # Warm-up\n",
    "    for _ in range(10):\n",
    "        _ = session.run(None, {input_name: input_data})\n",
    "\n",
    "    # Benchmark\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_runs):\n",
    "        _ = session.run(None, {input_name: input_data})\n",
    "    end_time = time.time() \n",
    "    \n",
    "    avg_latency_ms = (end_time - start_time) * 1000 / n_runs\n",
    "    print(f\"Avg inference time over {n_runs} runs: {avg_latency_ms:.2f} ms\")\n",
    "    return avg_latency_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_openvino_model(model_path, input_shape, device=\"CPU\", n_runs=100):\n",
    "    print(f\"\\nBenchmarking OpenVINO FP32 model: {model_path}\")\n",
    "    \n",
    "    core = ov.Core()\n",
    "    model = core.read_model(model=model_path)\n",
    "    compiled_model = core.compile_model(model=model, device_name=device)\n",
    "\n",
    "    # Dummy input\n",
    "    input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "    #input_data = cv2.imread(\"test.png\").astype(np.float32)\n",
    "\n",
    "    if \"rec\" in model_path:\n",
    "        input_data = resize_norm_img_rec(input_data)\n",
    "    if \"det\" in model_path:\n",
    "        input_data = resize_image_det(input_data)\n",
    "\n",
    "    # VÃ©rifiez que input_data est un tableau NumPy\n",
    "    if not isinstance(input_data, np.ndarray):\n",
    "        input_data = np.array(input_data)\n",
    "\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(10):\n",
    "        compiled_model([input_data])\n",
    "\n",
    "    # Benchmark\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_runs):\n",
    "        _ = compiled_model([input_data])\n",
    "    end_time = time.time()\n",
    "\n",
    "    avg_latency_ms = (end_time - start_time) * 1000 / n_runs\n",
    "    print(f\"Avg inference time over {n_runs} runs: {avg_latency_ms:.2f} ms\")\n",
    "    return avg_latency_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43857c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Quantize to INT8 with NNCF\n",
    "\n",
    "def quantize_openvino_model(model_path):\n",
    "    print(f\"\\nQuantizing model with NNCF: {model_path}\")\n",
    "    model_name = model_path.replace(\"_openvino_fp32.xml\", \"_openvino_int8\")\n",
    "    xml_path = str(Path(quantized_models_dir) / f\"{model_name}.xml\")\n",
    "\n",
    "    if Path(xml_path).exists():\n",
    "        print(f\"Quantized model already exists: {xml_path}... Skiping quantization.\")\n",
    "        return\n",
    "\n",
    "    core = ov.Core()\n",
    "    model = core.read_model(model=model_path)\n",
    "\n",
    "    def transform_fn(data_item: dict):\n",
    "        input_tensor = data_item[0].numpy()\n",
    "        return input_tensor\n",
    "\n",
    "    quantization_dataset = nncf.Dataset(test_loader)\n",
    "\n",
    "    quantized_model = nncf.quantize(\n",
    "        model,\n",
    "        quantization_dataset,\n",
    "        subset_size=len(test_loader),\n",
    "        preset=nncf.QuantizationPreset.MIXED\n",
    "    )\n",
    "\n",
    "    # Save the model in OpenVINO IR format\n",
    "    ov.save_model(quantized_model, xml_path)\n",
    "\n",
    "    print(f\"Quantized model saved to: {xml_path}\")\n",
    "\n",
    "quantize_openvino_model(det_model_path.replace(\".onnx\", \"_openvino_fp32.xml\"))\n",
    "quantize_openvino_model(rec_model_path.replace(\".onnx\", \"_openvino_fp32.xml\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Main execution\n",
    "for model_path in [det_model_path, rec_model_path]:\n",
    "    input_shape = input_shapes[os.path.basename(model_path)]\n",
    "    fp32_onxx_time = benchmark_onnxruntime(model_path, input_shape)\n",
    "    fp32_openvino_time = benchmark_openvino_model(model_path.replace(\".onnx\", \"_openvino_fp32.xml\"), input_shape)\n",
    "    int8_time = benchmark_openvino_model(model_path.replace(\".onnx\", \"_openvino_int8.xml\"), input_shape)\n",
    "    print(f\"\\n--- Results for {os.path.basename(model_path)} ---\")\n",
    "    print(f\"FP32 ONNX Runtime inference time : {fp32_onxx_time*1000:.2f} ms\")\n",
    "    print(f\"FP32 OpenVino Runtime inference time : {fp32_openvino_time*1000:.2f} ms\")\n",
    "    print(f\"INT8 NNCF quantized inference time : {int8_time*1000:.2f} ms\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
